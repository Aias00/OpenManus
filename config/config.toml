# Global LLM configuration
[llm]
model = "gpt-4o-mini"
base_url = "https://openiapi.com/v1"
api_key = "sk-ySxOaSp6ugzTasVZqIoueNrvZcwnzNpwdZk8HAFqY1NqPDpF"
max_tokens = 4096
temperature = 0.0
